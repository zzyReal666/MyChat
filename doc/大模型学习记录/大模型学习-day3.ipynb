{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e4aee7",
   "metadata": {},
   "source": [
    "# 大模型学习day3\n",
    "今天开始换个方式学习，使用cursor帮我生成一个项目，边教我大模型应用中技术比如Langchain，边完善这个工程项目，我使用cursor直接生成了python web的框架，fastAPI+postgres数据库，页面和后端尽可能使用cursor生成，这些对我没有太大的意义。除此之外还生成了CI/CD和dockerfile，这部分可以学习一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8daeda",
   "metadata": {},
   "source": [
    "## 一、RAG最小Demo（Langchain + 本地知识库 + 大模型）\n",
    "核心流程：\n",
    "- 用户输入问题\n",
    "- 检索知识库中相关文档片段\n",
    "- 将检索结果与用户问题拼接，作为Prompt输入大模型\n",
    "- 大模型生成最终答案\n",
    "\n",
    "下面实现RAG Demo代码（可直接在Python脚本中运行），先安装langchain, sentence-transformers, milvus, openai等依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  查看当前解释器目录 排查jupyter环境问题 在此之前先创建虚拟环境\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1b4dd",
   "metadata": {},
   "source": [
    "### 1.先安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "! pip install langchain sentence-transformers pymilvus openai langchain_openai\n",
    "! pip install -U langchain-community\n",
    "! pip install dashscope\n",
    "! pip install faiss-cpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da06691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独执行下确认依赖已经下载\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.llms import OpenAI  # 你可以换成ChatGLM、Qwen等\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54dda2",
   "metadata": {},
   "source": [
    "### 2.测试下是否能连接到大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认能加载大模型 这是openai的sdk\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    #打印环境变量\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？\"},\n",
    "    ],\n",
    "    # Qwen3模型通过enable_thinking参数控制思考过程（开源版默认True，商业版默认False）\n",
    "    # 使用Qwen3开源版模型时，若未启用流式输出，请将下行取消注释，否则会报错\n",
    "    # extra_body={\"enable_thinking\": False},\n",
    ")\n",
    "print(completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd61c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用langchain加载大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    temperature=0,\n",
    "    api_key=api_key, \n",
    "    base_url=base_url)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名字大师，请模仿实例起三个{country}名字，比如男孩名字经常叫做{boy_name}，女孩名字经常叫做{girl_name}\")\n",
    "message = prompt.format(country=\"中国特色的\", boy_name=\"高义\", girl_name=\"白洁\")\n",
    "\n",
    "print(message)\n",
    "response = llm.invoke(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3a223",
   "metadata": {},
   "source": [
    "### 3.RAG的最小demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import DashScopeEmbeddings\n",
    "from langchain.vectorstores import FAISS  # 推荐本地开发用FAISS\n",
    "from langchain.llms import OpenAI  # 你可以换成Qwen的Langchain适配器\n",
    "from langchain.chains import RetrievalQA\n",
    "from pydantic import SecretStr\n",
    "\n",
    "\n",
    "# 1. 设置阿里百炼 API Key\n",
    "import os\n",
    "key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "# print(os.getenv(\"DASHSCOPE_API_KEY\"))\n",
    "if key is not None:\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = key\n",
    "else:\n",
    "    raise ValueError(\"环境变量 DASHSCOPE_API_KEY 未设置！\")\n",
    "\n",
    "# 2. 加载阿里百炼 Embedding\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v4\")  # 或 text-embedding-v4，具体看你key支持的版本\n",
    "\n",
    "# 3. 构建本地FAISS向量库（假设你已有文档数据）\n",
    "from langchain.schema import Document\n",
    "docs = [\"Langchain是一个用于构建RAG应用的框架。\", \"RAG结合了检索和生成模型。\"]\n",
    "documents = [Document(page_content=doc) for doc in docs]\n",
    "vector_db = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# 4. 加载大模型（如用Qwen/通义千问，可用Langchain适配器，暂用OpenAI做演示）\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    temperature=0,\n",
    "    api_key=SecretStr(key), \n",
    "    base_url=base_url)\n",
    "\n",
    "# 5. 构建RAG链\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 6. 用户提问\n",
    "question = \"Langchain的RAG原理是什么？\"\n",
    "result = qa({\"query\": question})\n",
    "\n",
    "print(\"答案：\", result[\"result\"])\n",
    "print(\"参考片段：\", [doc.page_content for doc in result[\"source_documents\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mychatvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
